{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.93 available  Update with 'pip install -U ultralytics'\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'\u001b[31m\u001b[1mpin_memory\u001b[0m' is not a valid YOLO argument. \n'\u001b[31m\u001b[1mfp16\u001b[0m' is not a valid YOLO argument. \n\n    Arguments received: ['yolo', '--f=c:\\\\Users\\\\HP\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v3c1cbe22b5930a0f8bcaf44ed26a39842956a284b.json']. Ultralytics 'yolo' commands use the following syntax:\n\n        yolo TASK MODE ARGS\n\n        Where   TASK (optional) is one of {'obb', 'segment', 'classify', 'detect', 'pose'}\n                MODE (required) is one of {'train', 'track', 'val', 'benchmark', 'predict', 'export'}\n                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n\n    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n        yolo train data=coco8.yaml model=yolov8n.pt epochs=10 lr0=0.01\n\n    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n        yolo predict model=yolov8n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n\n    3. Val a pretrained detection model at batch-size 1 and image size 640:\n        yolo val model=yolov8n.pt data=coco8.yaml batch=1 imgsz=640\n\n    4. Export a YOLOv8n classification model to ONNX format at image size 224 by 128 (no TASK required)\n        yolo export model=yolov8n-cls.pt format=onnx imgsz=224,128\n\n    5. Explore your datasets using semantic search and SQL with a simple GUI powered by Ultralytics Explorer API\n        yolo explorer data=data.yaml model=yolov8n.pt\n    \n    6. Streamlit real-time webcam inference GUI\n        yolo streamlit-predict\n        \n    7. Run special commands:\n        yolo help\n        yolo checks\n        yolo version\n        yolo settings\n        yolo copy-cfg\n        yolo cfg\n\n    Docs: https://docs.ultralytics.com\n    Community: https://community.ultralytics.com\n    GitHub: https://github.com/ultralytics/ultralytics\n     (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32mg:\\applications\\envs\\person\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3577\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[20], line 8\u001b[0m\n    model.train(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mg:\\applications\\envs\\person\\Lib\\site-packages\\ultralytics\\engine\\model.py:809\u001b[0m in \u001b[0;35mtrain\u001b[0m\n    self.trainer = (trainer or self._smart_load(\"trainer\"))(overrides=args, _callbacks=self.callbacks)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mg:\\applications\\envs\\person\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:102\u001b[0m in \u001b[0;35m__init__\u001b[0m\n    self.args = get_cfg(cfg, overrides)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mg:\\applications\\envs\\person\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py:255\u001b[0m in \u001b[0;35mget_cfg\u001b[0m\n    check_dict_alignment(cfg, overrides)\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32mg:\\applications\\envs\\person\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py:440\u001b[1;36m in \u001b[1;35mcheck_dict_alignment\u001b[1;36m\n\u001b[1;33m    raise SyntaxError(string + CLI_HELP_MSG) from e\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m<string>\u001b[1;36m\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m '\u001b[31m\u001b[1mpin_memory\u001b[0m' is not a valid YOLO argument. \n'\u001b[31m\u001b[1mfp16\u001b[0m' is not a valid YOLO argument. \n\n    Arguments received: ['yolo', '--f=c:\\\\Users\\\\HP\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v3c1cbe22b5930a0f8bcaf44ed26a39842956a284b.json']. Ultralytics 'yolo' commands use the following syntax:\n\n        yolo TASK MODE ARGS\n\n        Where   TASK (optional) is one of {'obb', 'segment', 'classify', 'detect', 'pose'}\n                MODE (required) is one of {'train', 'track', 'val', 'benchmark', 'predict', 'export'}\n                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n\n    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n        yolo train data=coco8.yaml model=yolov8n.pt epochs=10 lr0=0.01\n\n    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n        yolo predict model=yolov8n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n\n    3. Val a pretrained detection model at batch-size 1 and image size 640:\n        yolo val model=yolov8n.pt data=coco8.yaml batch=1 imgsz=640\n\n    4. Export a YOLOv8n classification model to ONNX format at image size 224 by 128 (no TASK required)\n        yolo export model=yolov8n-cls.pt format=onnx imgsz=224,128\n\n    5. Explore your datasets using semantic search and SQL with a simple GUI powered by Ultralytics Explorer API\n        yolo explorer data=data.yaml model=yolov8n.pt\n    \n    6. Streamlit real-time webcam inference GUI\n        yolo streamlit-predict\n        \n    7. Run special commands:\n        yolo help\n        yolo checks\n        yolo version\n        yolo settings\n        yolo copy-cfg\n        yolo cfg\n\n    Docs: https://docs.ultralytics.com\n    Community: https://community.ultralytics.com\n    GitHub: https://github.com/ultralytics/ultralytics\n    \n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load the YOLOv8n model architecture without pre-trained weights\n",
    "    model = YOLO('yolov8n.yaml')  # Load the model architecture\n",
    "\n",
    "    # Resume training from the latest checkpoint\n",
    "    model.train(\n",
    "        data='G:/projects/code/data.yaml',   # Path to your dataset YAML file\n",
    "        device='cuda',                       # Use 'cuda' for GPU or 'cpu' for CPU\n",
    "        epochs=100,                          # Number of training epochs\n",
    "        imgsz=640,                           # Use largest image size that fits in GPU memory\n",
    "        batch=32,                            # Increase batch size if GPU memory allows\n",
    "        name='yolov8n_person_scratch',       # Experiment name\n",
    "        workers=16,                          # Use a high number of workers to utilize CPU cores\n",
    "        verbose=True,                        # Display detailed training logs\n",
    "        patience=100,                        # Early stopping after 100 epochs with no improvement\n",
    "        save=True,                           # Enable saving model checkpoints after each epoch\n",
    "        exist_ok=True,                       # Prevent overwriting existing models by saving to a unique name\n",
    "        fp16=True,                           # Enable mixed precision training for faster training and lower memory usage\n",
    "        pin_memory=True,                     # Enable pin memory for faster data loading into GPU\n",
    "        resume=True                          # Resume training from the latest checkpoint\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "person",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
